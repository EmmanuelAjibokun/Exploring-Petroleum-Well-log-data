{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e9d1e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import lasio\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f88f0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train data\n",
    "las1=lasio.read(\"well-log-data/31_2-21 S.las\")\n",
    "las2=lasio.read(\"well-log-data/25_6-3.las\")\n",
    "las3=lasio.read(\"well-log-data/25_11-5.las\")\n",
    "las4=lasio.read(\"well-log-data/16_8-1.las\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e0244ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to data frame\n",
    "df1=las1.df()\n",
    "df2=las2.df()\n",
    "df3=las3.df()\n",
    "df4=las4.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de414d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns that are not mutual\n",
    "df1=df1.drop([\"BS\", \"ROPA\", \"DTS\", \"PEF\", \"DRHO\"], axis=1)\n",
    "df2=df2.drop([\"BS\", \"MUDWEIGHT\", \"RSHA\", \"RMIC\",\"SP\", \"DTS\"], axis=1)\n",
    "df3=df3.drop([\"BS\", \"DCAL\", \"MUDWEIGHT\", \"SP\", \"DRHO\"], axis=1)\n",
    "df4=df4.drop([\"MUDWEIGHT\",\"SP\",\"DRHO\",\"RSHA\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74587381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "las_files_path = \"TRAIN_DATA\"\n",
    "las_files = [f for f in os.listdir(las_files_path) if f.endswith('.las.txt') ]\n",
    "len(las_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "221deac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1920355 entries, 0 to 1920354\n",
      "Data columns (total 26 columns):\n",
      " #   Column                             Dtype  \n",
      "---  ------                             -----  \n",
      " 0   FORCE_2020_LITHOFACIES_CONFIDENCE  float64\n",
      " 1   FORCE_2020_LITHOFACIES_LITHOLOGY   float64\n",
      " 2   CALI                               float64\n",
      " 3   MUDWEIGHT                          float64\n",
      " 4   ROP                                float64\n",
      " 5   RDEP                               float64\n",
      " 6   RSHA                               float64\n",
      " 7   RMED                               float64\n",
      " 8   RXO                                float64\n",
      " 9   SP                                 float64\n",
      " 10  DTC                                float64\n",
      " 11  NPHI                               float64\n",
      " 12  PEF                                float64\n",
      " 13  GR                                 float64\n",
      " 14  RHOB                               float64\n",
      " 15  DRHO                               float64\n",
      " 16  DEPTH_MD                           float64\n",
      " 17  X_LOC                              float64\n",
      " 18  Y_LOC                              float64\n",
      " 19  Z_LOC                              float64\n",
      " 20  BS                                 float64\n",
      " 21  DCAL                               float64\n",
      " 22  SGR                                float64\n",
      " 23  ROPA                               float64\n",
      " 24  DTS                                float64\n",
      " 25  RMIC                               float64\n",
      "dtypes: float64(26)\n",
      "memory usage: 380.9 MB\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for las_file in las_files:\n",
    "    # Read the LAS file\n",
    "    las = lasio.read(os.path.join(las_files_path, las_file))\n",
    "    # Convert to pandas DataFrame\n",
    "    df = las.df()\n",
    "    # Append the DataFrame to the list\n",
    "    dfs.append(df)\n",
    "\n",
    "mega_merged_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "mega_merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55609860",
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_merged_df = mega_merged_df.dropna(subset=[\"NPHI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35215b09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 859983 entries, 7327 to 1920135\n",
      "Data columns (total 26 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   FORCE_2020_LITHOFACIES_CONFIDENCE  821521 non-null  float64\n",
      " 1   FORCE_2020_LITHOFACIES_LITHOLOGY   814805 non-null  float64\n",
      " 2   CALI                               826539 non-null  float64\n",
      " 3   MUDWEIGHT                          224899 non-null  float64\n",
      " 4   ROP                                438610 non-null  float64\n",
      " 5   RDEP                               855691 non-null  float64\n",
      " 6   RSHA                               476065 non-null  float64\n",
      " 7   RMED                               841338 non-null  float64\n",
      " 8   RXO                                244469 non-null  float64\n",
      " 9   SP                                 573919 non-null  float64\n",
      " 10  DTC                                840219 non-null  float64\n",
      " 11  NPHI                               859983 non-null  float64\n",
      " 12  PEF                                532846 non-null  float64\n",
      " 13  GR                                 857003 non-null  float64\n",
      " 14  RHOB                               841524 non-null  float64\n",
      " 15  DRHO                               816891 non-null  float64\n",
      " 16  DEPTH_MD                           855978 non-null  float64\n",
      " 17  X_LOC                              855978 non-null  float64\n",
      " 18  Y_LOC                              855978 non-null  float64\n",
      " 19  Z_LOC                              855978 non-null  float64\n",
      " 20  BS                                 530653 non-null  float64\n",
      " 21  DCAL                               222434 non-null  float64\n",
      " 22  SGR                                57910 non-null   float64\n",
      " 23  ROPA                               214549 non-null  float64\n",
      " 24  DTS                                204270 non-null  float64\n",
      " 25  RMIC                               129822 non-null  float64\n",
      "dtypes: float64(26)\n",
      "memory usage: 177.2 MB\n"
     ]
    }
   ],
   "source": [
    "mega_merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c98972e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 859983 entries, 7327 to 1920135\n",
      "Data columns (total 26 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   FORCE_2020_LITHOFACIES_CONFIDENCE  859983 non-null  float64\n",
      " 1   FORCE_2020_LITHOFACIES_LITHOLOGY   859983 non-null  float64\n",
      " 2   CALI                               859983 non-null  float64\n",
      " 3   MUDWEIGHT                          859983 non-null  float64\n",
      " 4   ROP                                859983 non-null  float64\n",
      " 5   RDEP                               859983 non-null  float64\n",
      " 6   RSHA                               859983 non-null  float64\n",
      " 7   RMED                               859983 non-null  float64\n",
      " 8   RXO                                859983 non-null  float64\n",
      " 9   SP                                 859983 non-null  float64\n",
      " 10  DTC                                859983 non-null  float64\n",
      " 11  NPHI                               859983 non-null  float64\n",
      " 12  PEF                                859983 non-null  float64\n",
      " 13  GR                                 859983 non-null  float64\n",
      " 14  RHOB                               859983 non-null  float64\n",
      " 15  DRHO                               859983 non-null  float64\n",
      " 16  DEPTH_MD                           859983 non-null  float64\n",
      " 17  X_LOC                              859983 non-null  float64\n",
      " 18  Y_LOC                              859983 non-null  float64\n",
      " 19  Z_LOC                              859983 non-null  float64\n",
      " 20  BS                                 859983 non-null  float64\n",
      " 21  DCAL                               859983 non-null  float64\n",
      " 22  SGR                                859983 non-null  float64\n",
      " 23  ROPA                               859983 non-null  float64\n",
      " 24  DTS                                859983 non-null  float64\n",
      " 25  RMIC                               859983 non-null  float64\n",
      "dtypes: float64(26)\n",
      "memory usage: 177.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Fill NaN values with the mean of each column\n",
    "mega_merged_df_filled = mega_merged_df.fillna(mega_merged_df.mean())\n",
    "mega_merged_df_filled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f68e23db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 859983 entries, 7327 to 1920135\n",
      "Data columns (total 9 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   FORCE_2020_LITHOFACIES_CONFIDENCE  859983 non-null  float64\n",
      " 1   FORCE_2020_LITHOFACIES_LITHOLOGY   859983 non-null  float64\n",
      " 2   RHOB                               859983 non-null  float64\n",
      " 3   RDEP                               859983 non-null  float64\n",
      " 4   GR                                 859983 non-null  float64\n",
      " 5   NPHI                               859983 non-null  float64\n",
      " 6   CALI                               859983 non-null  float64\n",
      " 7   RMED                               859983 non-null  float64\n",
      " 8   DRHO                               859983 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 65.6 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FORCE_2020_LITHOFACIES_CONFIDENCE</th>\n",
       "      <th>FORCE_2020_LITHOFACIES_LITHOLOGY</th>\n",
       "      <th>RHOB</th>\n",
       "      <th>RDEP</th>\n",
       "      <th>GR</th>\n",
       "      <th>NPHI</th>\n",
       "      <th>CALI</th>\n",
       "      <th>RMED</th>\n",
       "      <th>DRHO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>859983.000000</td>\n",
       "      <td>859983.000000</td>\n",
       "      <td>859983.000000</td>\n",
       "      <td>859983.000000</td>\n",
       "      <td>859983.000000</td>\n",
       "      <td>859983.000000</td>\n",
       "      <td>859983.000000</td>\n",
       "      <td>859983.000000</td>\n",
       "      <td>859983.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.120960</td>\n",
       "      <td>61345.448106</td>\n",
       "      <td>2.311291</td>\n",
       "      <td>14.175132</td>\n",
       "      <td>74.111380</td>\n",
       "      <td>0.339272</td>\n",
       "      <td>11.851067</td>\n",
       "      <td>5.260001</td>\n",
       "      <td>0.013340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.368813</td>\n",
       "      <td>13681.600065</td>\n",
       "      <td>0.240437</td>\n",
       "      <td>135.950685</td>\n",
       "      <td>34.166210</td>\n",
       "      <td>0.133661</td>\n",
       "      <td>2.965679</td>\n",
       "      <td>53.568049</td>\n",
       "      <td>0.187601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046385</td>\n",
       "      <td>-6.382940</td>\n",
       "      <td>-0.037328</td>\n",
       "      <td>2.340806</td>\n",
       "      <td>-0.008419</td>\n",
       "      <td>-6.925800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>65000.000000</td>\n",
       "      <td>2.141013</td>\n",
       "      <td>0.989215</td>\n",
       "      <td>51.846319</td>\n",
       "      <td>0.246315</td>\n",
       "      <td>8.957843</td>\n",
       "      <td>0.996669</td>\n",
       "      <td>-0.007691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>65000.000000</td>\n",
       "      <td>2.339545</td>\n",
       "      <td>1.568777</td>\n",
       "      <td>73.059875</td>\n",
       "      <td>0.333877</td>\n",
       "      <td>12.203342</td>\n",
       "      <td>1.663670</td>\n",
       "      <td>0.004249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>65000.000000</td>\n",
       "      <td>2.496742</td>\n",
       "      <td>2.997131</td>\n",
       "      <td>92.065140</td>\n",
       "      <td>0.438660</td>\n",
       "      <td>12.918489</td>\n",
       "      <td>3.352700</td>\n",
       "      <td>0.021223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>99000.000000</td>\n",
       "      <td>3.357802</td>\n",
       "      <td>1999.887085</td>\n",
       "      <td>1141.292114</td>\n",
       "      <td>0.999570</td>\n",
       "      <td>32.111065</td>\n",
       "      <td>1996.104614</td>\n",
       "      <td>49.834522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       FORCE_2020_LITHOFACIES_CONFIDENCE  FORCE_2020_LITHOFACIES_LITHOLOGY  \\\n",
       "count                      859983.000000                     859983.000000   \n",
       "mean                            1.120960                      61345.448106   \n",
       "std                             0.368813                      13681.600065   \n",
       "min                             1.000000                      30000.000000   \n",
       "25%                             1.000000                      65000.000000   \n",
       "50%                             1.000000                      65000.000000   \n",
       "75%                             1.000000                      65000.000000   \n",
       "max                             3.000000                      99000.000000   \n",
       "\n",
       "                RHOB           RDEP             GR           NPHI  \\\n",
       "count  859983.000000  859983.000000  859983.000000  859983.000000   \n",
       "mean        2.311291      14.175132      74.111380       0.339272   \n",
       "std         0.240437     135.950685      34.166210       0.133661   \n",
       "min         0.000000       0.046385      -6.382940      -0.037328   \n",
       "25%         2.141013       0.989215      51.846319       0.246315   \n",
       "50%         2.339545       1.568777      73.059875       0.333877   \n",
       "75%         2.496742       2.997131      92.065140       0.438660   \n",
       "max         3.357802    1999.887085    1141.292114       0.999570   \n",
       "\n",
       "                CALI           RMED           DRHO  \n",
       "count  859983.000000  859983.000000  859983.000000  \n",
       "mean       11.851067       5.260001       0.013340  \n",
       "std         2.965679      53.568049       0.187601  \n",
       "min         2.340806      -0.008419      -6.925800  \n",
       "25%         8.957843       0.996669      -0.007691  \n",
       "50%        12.203342       1.663670       0.004249  \n",
       "75%        12.918489       3.352700       0.021223  \n",
       "max        32.111065    1996.104614      49.834522  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\"FORCE_2020_LITHOFACIES_CONFIDENCE\", \"FORCE_2020_LITHOFACIES_LITHOLOGY\", \"RHOB\", \"RDEP\", \"GR\", \"NPHI\", \"CALI\", \"RMED\", \"DRHO\"]\n",
    "featured_df = mega_merged_df_filled[col]\n",
    "featured_df.info()\n",
    "featured_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f1c8948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5827 entries, 2381.382 to 3266.934\n",
      "Data columns (total 9 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   FORCE_2020_LITHOFACIES_CONFIDENCE  2400 non-null   float64\n",
      " 1   FORCE_2020_LITHOFACIES_LITHOLOGY   2404 non-null   float64\n",
      " 2   RHOB                               2175 non-null   float64\n",
      " 3   RDEP                               5827 non-null   float64\n",
      " 4   GR                                 5827 non-null   float64\n",
      " 5   NPHI                               5827 non-null   float64\n",
      " 6   CALI                               2404 non-null   float64\n",
      " 7   RMED                               5776 non-null   float64\n",
      " 8   DRHO                               2404 non-null   float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 455.2 KB\n"
     ]
    }
   ],
   "source": [
    "#import test data\n",
    "las5=lasio.read(\"TEST_DATA/35_11-13.las.txt\")\n",
    "test_df=las5.df()\n",
    "\n",
    "# Filter\n",
    "test_df = test_df.dropna(subset=[\"NPHI\"])\n",
    "test_df = test_df[col]\n",
    "# test_df_filled = test_df.fillna(clean_mega_merged_df.mean())\n",
    "\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f009c376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2172 entries, 2936.486 to 3266.934\n",
      "Data columns (total 9 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   FORCE_2020_LITHOFACIES_CONFIDENCE  2172 non-null   float64\n",
      " 1   FORCE_2020_LITHOFACIES_LITHOLOGY   2172 non-null   float64\n",
      " 2   RHOB                               2172 non-null   float64\n",
      " 3   RDEP                               2172 non-null   float64\n",
      " 4   GR                                 2172 non-null   float64\n",
      " 5   NPHI                               2172 non-null   float64\n",
      " 6   CALI                               2172 non-null   float64\n",
      " 7   RMED                               2172 non-null   float64\n",
      " 8   DRHO                               2172 non-null   float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 169.7 KB\n"
     ]
    }
   ],
   "source": [
    "test_df= test_df.dropna()\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bae27eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    np.random.seed(42)\n",
    "\n",
    "    x= df.drop([\"NPHI\"], axis=1)\n",
    "    y=df[\"NPHI\"]\n",
    "\n",
    "    #train data\n",
    "    x_train, y_train= (x,y)\n",
    "\n",
    "    #select a model\n",
    "    pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # or your chosen strategy  \n",
    "    ('classifier', RandomForestRegressor())\n",
    "    ])\n",
    "    # Fit the pipeline on your training data\n",
    "    pipeline.fit(x_train, y_train)\n",
    "\n",
    "#     model = RandomForestClassifier()\n",
    "\n",
    "    #fit model\n",
    "#     model.fit(x_train, y_train)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a672aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_boost(df):\n",
    "    import xgboost as xgb\n",
    "    np.random.seed(42)\n",
    "\n",
    "    x= df.drop([\"NPHI\"], axis=1)\n",
    "    y=df[\"NPHI\"]\n",
    "\n",
    "\n",
    "    #train data\n",
    "    x_train, y_train= (x,y)\n",
    "\n",
    "    #select a model\n",
    "    model=xgb.XGBRegressor()\n",
    "\n",
    "    #fit model\n",
    "    model.fit(x_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d851148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_double(df):\n",
    "    import xgboost as xgb\n",
    "    np.random.seed(42)\n",
    "\n",
    "    x= df.drop([\"NPHI\"], axis=1)\n",
    "    y=df[\"NPHI\"]\n",
    "\n",
    "\n",
    "    #train data\n",
    "    x_train, y_train= (x,y)\n",
    "\n",
    "    #select a model\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=800,          # Number of trees in the forest\n",
    "        max_depth=10,              # Maximum depth of each tree\n",
    "        min_samples_split=2,       # Minimum number of samples required to split an internal node\n",
    "        min_samples_leaf=1,        # Minimum number of samples required to be at a leaf node\n",
    "        max_features='log2',       # Number of features to consider when looking for the best split\n",
    "        bootstrap=True,            # Whether bootstrap samples are used when building trees\n",
    "        n_jobs=os.cpu_count(),     # Number of jobs to run in parallel (uses all CPUs)\n",
    "        random_state=100           # Random seed for reproducibility\n",
    "    )\n",
    "\n",
    "    xgboost_model = xgb.XGBClassifier(model,learning_rate=0.2, n_estimators=800, max_depth=10,\n",
    "                               min_child_weight=1, gamma=0, subsample=0.6, \n",
    "                               colsample_bytree=0.6, reg_alpha=0, reg_lambda=1, \n",
    "                               objective='multi:softmax', \n",
    "                               nthread=os.cpu_count(), scale_pos_weight=1,tree_method='hist', seed=100)\n",
    "\n",
    "    #fit model\n",
    "    model.fit(x_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a49d74c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23322957241771536"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = train_model(featured_df)\n",
    "\n",
    "x=test_df.drop([\"NPHI\"], axis=1)\n",
    "y=test_df[\"NPHI\"]\n",
    "\n",
    "x_test, y_test=(x,y)\n",
    "\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83923691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31671890456480034"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = train_model_boost(featured_df)\n",
    "\n",
    "x=test_df.drop([\"NPHI\"], axis=1)\n",
    "y=test_df[\"NPHI\"]\n",
    "\n",
    "x_test, y_test=(x,y)\n",
    "\n",
    "model2.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fba18f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0695b72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.317\n",
      "Scikit-learn MAE Calculation: 0.05659674473531506\n"
     ]
    }
   ],
   "source": [
    "# Calculate MAE using scikit-learn  \n",
    "mae_sklearn = mean_absolute_error(y_test, y_preds)\n",
    "\n",
    "# Calculate R²  \n",
    "r2 = r2_score(y_test, y_preds)  \n",
    "print(f'R-squared: {r2:.3f}') \n",
    "print(f'Scikit-learn MAE Calculation: {mae_sklearn}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe792b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f729eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lasio\n",
    "from os import path\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.stats import probplot, pearsonr\n",
    "from warnings import filterwarnings\n",
    "from colorama import Fore\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "filterwarnings('ignore')\n",
    "\n",
    "#setting defaults\n",
    "pd.options.display.max_columns = 15\n",
    "pd.options.display.max_rows = 40\n",
    "# plt.style.use('ggplot')\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e05e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select columns to use in the dataframe\n",
    "col = ['DEPT:1','GR', 'RT', 'RHOB', 'SP', 'CALI', 'PHI']\n",
    "\n",
    "def fillArbitrary(dfs:pd.DataFrame) -> 'pd.Series|pd.DataFrame':\n",
    "    \"\"\"\n",
    "   fill in missing values in the dataframes with mean value\n",
    "    \"\"\"\n",
    "    df = dfs.copy()\n",
    "    df.dropna(axis='index', subset=['PHI'], inplace=True)\n",
    "    for c in df.columns:\n",
    "        df[c].fillna(df[c].mean(), inplace=True)\n",
    "        \n",
    "    depth = df['DEPTH'] #new depth range after dropping rows where nphi and sp are null\n",
    "    \n",
    "    df.drop(['DEPTH'], axis='columns', inplace=True) #dropping poorly correlating features\n",
    "    \n",
    "    return df, depth\n",
    "\n",
    "def processData(well:pd.DataFrame, cols:list, name:str) -> 'tuple|pd.DataFrame':\n",
    "    \n",
    "    '''\n",
    "    cleans and process the train dataframe for null values\n",
    "    \n",
    "    '''\n",
    "#     column = cols[:-2]\n",
    "    df = well.filter(cols, axis='columns')\n",
    "    \n",
    "    #filtering odd values in features \n",
    "    df['SP'] = np.where(df['SP'] < 0, np.nan, df['SP'])\n",
    "    df['PHI'] = np.where(df['PHI'] < 0, np.nan, df['PHI'])\n",
    "    #rename column\n",
    "    df = df.rename({'DEPT:1':'DEPTH'}, axis='columns')\n",
    "    df['RT'] = np.log10(df['RT']) #transforms the RT log to logarithmic scale\n",
    "    \n",
    "    #filter data to region where PHI readings are available\n",
    "    if name == 'WellB':\n",
    "        df = df[(df['DEPTH'] >= 2500) & (df['DEPTH'] <= 4200)]\n",
    "    else:\n",
    "        df = df[(df['DEPTH'] >= 3000) & (df['DEPTH'] <= 3600)]\n",
    "    \n",
    "    #calling the arbitrtary fill function\n",
    "    newdf, depth = fillArbitrary(df)\n",
    "    newdf['DEPTH'] = depth #adding new depth sequence to df\n",
    "    newdf = newdf.reset_index(drop=True).sort_values('DEPTH')\n",
    "\n",
    "    return newdf, df.shape\n",
    "\n",
    "def qq_plot_historesids(y_true, y_pred, name):\n",
    "    '''\n",
    "    quantile-quantile and histogram residual plots\n",
    "    '''\n",
    "    sns.set_style('darkgrid')\n",
    "    plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "    plt.suptitle(f'Metrics Plot for {name}', fontsize=20)\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    resids = np.subtract(y_true.reshape(-1,1), y_pred.reshape(-1,1))\n",
    "    sns.distplot(resids)\n",
    "    plt.title(f'Histogram of residuals for {name}')\n",
    "    plt.xlabel('Residual value')\n",
    "    plt.ylabel('count')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    resids = np.subtract(y_true, y_pred)\n",
    "    r2 = round(r2_score(y_true, y_pred), 2)\n",
    "    r2_adj = round(r2 - (6 - 1)/(y_true.shape[0] - 6) * (1 - r2), 2)\n",
    "    probplot(resids.flatten(), plot = plt)\n",
    "    plt.title(f'Residuals vs. Prediction for {name}')\n",
    "    plt.text(-2, 5, 'Adjusted R2 = ' + r2_adj.astype(str), fontsize=10, c='red')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.xlabel('Predicted Values')\n",
    "\n",
    "    \n",
    "def chatterjeeCorr(df:pd.DataFrame, x:str, y:str) -> float:\n",
    "    '''\n",
    "    implementing chatterjee method of calculating non-linear relationship between \n",
    "    independent and dependent variables\n",
    "    '''\n",
    "    dfs = df.copy()\n",
    "    dfs['x_rk'] = dfs[x].rank()\n",
    "    dfs['y_rk'] = dfs[y].rank()\n",
    "    dfs = dfs.sort_values('x_rk')\n",
    "    sum_term = dfs['y_rk'].diff().abs().sum()\n",
    "    chatt_corr = (1 - 3 * sum_term / (pow(dfs.shape[0], 2) - 1))\n",
    "    return chatt_corr\n",
    "\n",
    "\n",
    "def plotScatter(df:pd.DataFrame, *cols:tuple, y='PHI', rel='linear'):\n",
    "    \n",
    "    sns.set_style('whitegrid')\n",
    "    plt.subplots(nrows=2, ncols=3, figsize=(22, 11))\n",
    "    plt.suptitle(f'Scatter Plot Relationship', fontsize=20)\n",
    "    for i, x in enumerate(cols):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        if x == 'RT':\n",
    "            plt.title(y + ' vs. log' + x)\n",
    "        else:\n",
    "            plt.title(y + ' vs. ' + x)\n",
    "        sns.regplot(x=x, y=y, data=df, color='blue',\n",
    "                   fit_reg=True, scatter_kws={'s':10, 'alpha':0.5})\n",
    "        \n",
    "        if rel == 'linear':\n",
    "            r, p_val = pearsonr(df[x], df[y])\n",
    "        elif rel == 'non-linear':\n",
    "            r = chatterjeeCorr(df, x, y)\n",
    "        if x == 'DEPTH':\n",
    "            plt.text(2600, 60, f'R = {r:.2f}', bbox=dict(facecolor='red', alpha=0.5))\n",
    "        elif x=='CALI':\n",
    "            plt.text(10, 60, f'R = {r:.2f}', bbox=dict(facecolor='red', alpha=0.5))\n",
    "        else:\n",
    "            plt.text(2, 60, f'R = {r:.2f}', bbox=dict(facecolor='red', alpha=0.5))\n",
    "            \n",
    "\n",
    "def log_plot(logs, x1, x2, x3, x4, x5, x6, x7, well_name, top, bot):\n",
    "    \n",
    "    '''\n",
    "    plot well logs along with the predicted and ground truth of porosity\n",
    "    '''\n",
    "    sns.set_style('white')\n",
    "    # ztop = logs.DEPTH.min(); zbot=logs.DEPTH.max()\n",
    "    \n",
    "#     logs['litho number'] = [1 if i >= (logs['GR'].max() - logs['GR'].min())/2 else 0 for i in logs['GR'] ]\n",
    "  \n",
    "    # color = ['black', 'red', 'blue', 'green', 'cyan', 'purple', 'purple']\n",
    "    title = ['GR(gAPI)', 'log(RT)(ohm-m)', 'RHOB(g/cm3)', 'SP(mV)', 'CALI(in)', 'PHI(m3/m3)', 'Pred PHI(m3/m3)']\n",
    "    \n",
    "    f, ax = plt.subplots(nrows=1, ncols=len(title), figsize=(14, 7))\n",
    "    f.suptitle(f'Curve Plotting for {well_name}', fontsize=20, y=1.05)\n",
    "    \n",
    "    ax[0].plot(logs[x1], logs.DEPTH, 'black'); ax[1].semilogx(logs[x2], logs.DEPTH, 'black')\n",
    "    ax[2].plot(logs[x3], logs.DEPTH, 'black'); ax[3].plot(logs[x4], logs.DEPTH,'black')\n",
    "    ax[4].plot(logs[x5], logs.DEPTH, 'black'); ax[5].plot(logs[x6], logs.DEPTH, 'green')\n",
    "    ax[6].plot(logs[x7], logs.DEPTH,'blue')\n",
    "\n",
    "   \n",
    "    for i in range(len(ax)):\n",
    "        ax[i].set_ylim(top,bot); ax[i].invert_yaxis()\n",
    "        if i != 1:\n",
    "            ax[i].locator_params(axis='x', nbins=3)\n",
    "        ax[i].xaxis.label.set_color('black')\n",
    "        ax[i].grid(True); ax[i].tick_params(axis='x', colors='black')\n",
    "        ax[i].spines['top'].set_edgecolor('black'); ax[i].set_title(title[i], pad=15)\n",
    "        ax[i].spines[\"top\"].set_position((\"axes\", 1.02)); ax[i].xaxis.set_ticks_position(\"top\")\n",
    "        ax[i].xaxis.set_label_position(\"top\")\n",
    "    \n",
    "\n",
    "    ax[0].set_xlim(logs[x1].min(), logs[x1].max()); ax[1].set_xlim(logs[x2].min(), logs[x2].max())\n",
    "    ax[2].set_xlim(logs[x3].min(), logs[x3].max()); ax[3].set_xlim(logs[x4].min(), logs[x4].max())\n",
    "    ax[4].set_xlim(logs[x5].min(), logs[x5].max()); ax[5].set_xlim(logs[x6].min(), logs[x6].max())\n",
    "    ax[6].set_xlim(logs[x6].min(), logs[x6].max());\n",
    "    \n",
    "def plot_scatter(df, well_name):    \n",
    "    '''\n",
    "    plots the predicted and true poro reading on scatter plot\n",
    "    '''\n",
    "    sns.set_style('darkgrid')\n",
    "    plt.figure(figsize=(5,5.5))\n",
    "    sns.scatterplot('PHI', 'Predicted PHI', data=df)\n",
    "    # if well_name\n",
    "    plt.plot([10, 60], [10, 60], '--', c='black')\n",
    "    plt.xlabel('True PHI')\n",
    "    plt.ylabel('Pred PHI')\n",
    "    plt.title(f'{well_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e53ba522",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(object):\n",
    "    '''\n",
    "    class to porosity prediction\n",
    "    '''\n",
    "    def __init__(self, train, test):\n",
    "        '''\n",
    "        takes in the train and test dataframe\n",
    "        '''\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        \n",
    "    def __call__(self, plot=True):\n",
    "        \n",
    "        return self._fit_predict(plot=plot)\n",
    "    \n",
    "    def describe(self, train):\n",
    "        '''\n",
    "        returns the new summary statistics of the dataframe\n",
    "        '''\n",
    "        if train:\n",
    "            return self.train.describe()\n",
    "        else: \n",
    "            return self.test.describe()\n",
    "    \n",
    "    def _preprocess(self, train, test):\n",
    "        \n",
    "        '''\n",
    "        desc: splits the train dataframe into 80% train and 20% test and scales the data\n",
    "        returns: robust-scaled numpy data\n",
    "        '''\n",
    "\n",
    "        #getting feature and target\n",
    "        train_feature = (self.train.drop('NPHI', axis='columns')).values;\n",
    "        test_feature = (self.test.drop('NPHI', axis='columns')).values\n",
    "        trainlabel = np.array((self.train['NPHI'])/100);\n",
    "        testlabel = np.array((self.test['NPHI'])/100)\n",
    "        \n",
    "        ## Randomly sample cases to create independent training and validation data\n",
    "        np.random.seed(9988)\n",
    "        indx = range(train_feature.shape[0])\n",
    "        indx = train_test_split(indx, test_size = 0.15)\n",
    "        x_train = train_feature[indx[0],:]; y_train = np.ravel(trainlabel[indx[0]])\n",
    "        x_test = train_feature[indx[1],:]; y_test = np.ravel(trainlabel[indx[1]])\n",
    "\n",
    "        #standardization for train and test\n",
    "        scaler = RobustScaler(quantile_range=(25.0, 75.0)).fit(x_train)\n",
    "        x_train = scaler.transform(x_train); x_test = scaler.transform(x_test)\n",
    "        trainfeature = scaler.transform(train_feature); testfeature = scaler.transform(test_feature)\n",
    "        \n",
    "        return x_train, x_test, y_train, y_test, trainfeature, trainlabel, testfeature, testlabel\n",
    "    \n",
    "    def _fit_predict(self, plot=True):\n",
    "        \n",
    "        '''\n",
    "        fits models on the data and returns the stacked PHI results\n",
    "        '''\n",
    "        x_train, x_test, y_train, y_test, trainfeature, trainlabel, testfeature, testlabel = self._preprocess(self.train, self.test)\n",
    "        \n",
    "        model1 = SVR(C=10, epsilon=0.1, kernel='rbf', gamma='auto', tol=1e-10)\n",
    "        model2 = MLPRegressor(hidden_layer_sizes=(5,), activation='relu', solver='adam',\n",
    "                                   random_state=300, alpha=1, validation_fraction=0.3)\n",
    "        #fitting model and prediction \n",
    "        model1.fit(x_train, y_train); model2.fit(x_train, y_train)\n",
    "        \n",
    "        #validation on well one\n",
    "        print(Fore.BLUE + 'Validation Results on Well 1')\n",
    "        print('-'*50)\n",
    "        \n",
    "        y_pred1_1 = (model1.predict(trainfeature))*100 #svr prediction\n",
    "        y_pred1_2 = (model2.predict(trainfeature))*100 #mlp prediction\n",
    "        trainlabel = trainlabel*100 #denormalise the train label\n",
    "        final1 = (y_pred1_1 + y_pred1_2)/2 # avg. prediction        \n",
    "        print('The R2-score of SVR for Well 1 : %.2f' %r2_score(trainlabel, y_pred1_1))\n",
    "        print('The R2-score of MLP for Well 1 : %.2f' %r2_score(trainlabel, y_pred1_2))\n",
    "        print('The Abso. Error of SVR for Well 1 : %.2f' %mean_absolute_error(trainlabel, y_pred1_1))\n",
    "        print('The Abso. Error of MLP for Well 1 : %.2f' %mean_absolute_error(trainlabel, y_pred1_2))\n",
    "        print('The Average R2 Score for Well 1 : %.2f' %r2_score(trainlabel, final1))\n",
    "        print('The Average Abso. Error for Well 1 : %.2f' %mean_absolute_error(trainlabel, final1))\n",
    "        print('The Average R for Well 1 : %.2f' %np.sqrt(r2_score(trainlabel, final1)))\n",
    "\n",
    "        \n",
    "        print()\n",
    "        #validation on well two\n",
    "        print(Fore.YELLOW + 'Validation Results on Well 2')\n",
    "        print('-'*50)\n",
    "        y_pred2_1 = (model1.predict(testfeature))*100 #svr prediction\n",
    "        y_pred2_2 = (model2.predict(testfeature))*100 #mlp prediction\n",
    "        testlabel = testlabel*100 #denormalise the validation label\n",
    "        final2 = (y_pred2_1 + y_pred2_2)/2 # avg. prediction\n",
    "        print('The R2-score of SVR for Well 2 : %.2f' %r2_score(testlabel, y_pred2_1))\n",
    "        print('The R2-score of MLP for Well 2 : %.2f' %r2_score(testlabel, y_pred2_2))\n",
    "        print('The Abso. Error of SVR for Well 2 : %.2f' %mean_absolute_error(testlabel, y_pred2_1))\n",
    "        print('The Abso. Error of MLP for Well 2 : %.2f' %mean_absolute_error(testlabel, y_pred2_2))\n",
    "        print('The Average R2 Score for Well 2 : %.2f' %r2_score(testlabel, final2))\n",
    "        print('The Average Abso. Error for Well 2 : %.2f' %mean_absolute_error(testlabel, final2))\n",
    "        print('The Average R for Well 2 : %.2f' %np.sqrt(r2_score(testlabel, final2)))\n",
    "        \n",
    "        if plot:\n",
    "            #plot qq-plot and histogram of residuals\n",
    "            qq_plot_historesids(trainlabel, final1, 'WELLA#')\n",
    "            qq_plot_historesids(testlabel, final2, 'WELLB#')\n",
    "\n",
    "\n",
    "        return final1, final2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac19504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all paths and alphabetically ordered\n",
    "# paths = sorted(glob.glob(os.path.join(\"./\", \"*.LAS\")))\n",
    "paths = ['WELLB#.las', 'WELLA#.las']\n",
    "well_df = [0] * 2\n",
    "\n",
    "for i in range(len(paths)):\n",
    "    # read with lasio and convert to dataframe\n",
    "    df = (lasio.read(path.join('./', paths[i]))).df()\n",
    "\n",
    "    well_df[i] = df.reset_index()\n",
    "\n",
    "well1, well2 = well_df\n",
    "\n",
    "well1, shape1=processData(well1, col, name='WellA') #validation\n",
    "well2, shape2=processData(well2, col, name='WellB') #training\n",
    "\n",
    "train = well2\n",
    "test = well1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cffe258",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=((13, 7)))\n",
    "corr = train.select_dtypes('float64').corr()\n",
    "sns.heatmap(corr, annot=True, vmin=0, vmax=1, linewidths=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd5c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScatter(train, 'DEPTH', 'GR', 'RHOB', 'CALI', 'SP', 'RT', rel='non-linear') #chatterjee\n",
    "plotScatter(train, 'DEPTH', 'GR', 'RHOB', 'CALI', 'SP', 'RT', rel='linear') #pearson's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a26f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel = BaseModel(train, test)\n",
    "well1_pred, well2_pred = basemodel(plot=True)\n",
    "\n",
    "#add predicted results to the original dataframes\n",
    "train['Predicted PHI'] = well1_pred\n",
    "test['Predicted PHI'] = well2_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f257fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation scatter plots\n",
    "plot_scatter(train, 'WellA#')\n",
    "plot_scatter(test, 'WellB#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e324475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log plots\n",
    "log_plot(train, 'GR', 'RT', 'RHOB', 'SP', 'CALI', 'PHI', 'Predicted PHI', well_name='WellA#',top=2500, bot=2700)\n",
    "log_plot(test, 'GR', 'RT', 'RHOB', 'SP', 'CALI', 'PHI', 'Predicted PHI', well_name='WellB#',top=3100, bot=3200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b37c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "132aa795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mValidation Results on Well 1\n",
      "--------------------------------------------------\n",
      "The R2-score of SVR for Well 1 : -1.13\n",
      "The R2-score of MLP for Well 1 : -144.25\n",
      "The Abso. Error of SVR for Well 1 : 0.16\n",
      "The Abso. Error of MLP for Well 1 : 0.72\n",
      "The Average R2 Score for Well 1 : -36.50\n",
      "The Average Abso. Error for Well 1 : 0.38\n",
      "The Average R for Well 1 : nan\n",
      "\n",
      "\u001b[33mValidation Results on Well 2\n",
      "--------------------------------------------------\n",
      "The R2-score of SVR for Well 2 : -4.38\n",
      "The R2-score of MLP for Well 2 : -222.97\n",
      "The Abso. Error of SVR for Well 2 : 0.18\n",
      "The Abso. Error of MLP for Well 2 : 0.88\n",
      "The Average R2 Score for Well 2 : -66.13\n",
      "The Average Abso. Error for Well 2 : 0.53\n",
      "The Average R for Well 2 : nan\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'qq_plot_historesids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m basemodel \u001b[38;5;241m=\u001b[39m BaseModel(featured_df, test_df)\n\u001b[1;32m----> 2\u001b[0m well1_pred, well2_pred \u001b[38;5;241m=\u001b[39m \u001b[43mbasemodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#add predicted results to the original dataframes\u001b[39;00m\n\u001b[0;32m      5\u001b[0m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted PHI\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m well1_pred\n",
      "Cell \u001b[1;32mIn[38], line 14\u001b[0m, in \u001b[0;36mBaseModel.__call__\u001b[1;34m(self, plot)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[38], line 100\u001b[0m, in \u001b[0;36mBaseModel._fit_predict\u001b[1;34m(self, plot)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe Average R for Well 2 : \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(r2_score(testlabel, final2)))\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plot:\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m#plot qq-plot and histogram of residuals\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     \u001b[43mqq_plot_historesids\u001b[49m(trainlabel, final1, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWELLA#\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    101\u001b[0m     qq_plot_historesids(testlabel, final2, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWELLB#\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final1, final2\n",
      "\u001b[1;31mNameError\u001b[0m: name 'qq_plot_historesids' is not defined"
     ]
    }
   ],
   "source": [
    "basemodel = BaseModel(featured_df, test_df)\n",
    "well1_pred, well2_pred = basemodel(plot=True)\n",
    "\n",
    "#add predicted results to the original dataframes\n",
    "train['Predicted PHI'] = well1_pred\n",
    "test['Predicted PHI'] = well2_pred\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6881855c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
